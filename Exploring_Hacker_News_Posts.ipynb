{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Exploring Hacker News Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we'll work with a dataset of submissions to a popular technology site known as Hacker News.\n",
    "\n",
    "Hacker News was started by the startup incubator Y Combinator, where user-submitted stories (known as \"posts\") receive votes and comments in a similar vein to Reddit. Hacker News is overly popular within technology and startup circles and hence, posts at the top of the Hacker News listings can get thousands of visitors as a result.\n",
    "\n",
    "The original data source in Kaggle which can be accessed here contains nearly 300,000 rows in total but this has been reduced to roughly 20,000 rows by removing submissions without any comments, then randomly sampling from the remaining observations. The descriptions of the columns are as follows:\n",
    "\n",
    "- **id**: the unique identifier from Hacker News for the post\n",
    "- **title**: the title of the post\n",
    "- **url**: the URL that the posts links to, if the post has a URL\n",
    "- **num_points**: the number of points the post acquired, - calculated as the total number of upvotes minus the total number of downvotes\n",
    "- **num_comments**: the number of comments on the post\n",
    "- **author**: the username of the person who submitted the post\n",
    "- **created_at**: the date and time of the post's submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we get started, we have to read in the data from the **hacker_news.csv** file as a list of lists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's print out the first five rows of our loaded dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at'], ['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']]\n"
     ]
    }
   ],
   "source": [
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Removing Headers from our Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the first list in the inner lists contains the column headers, and the lists after contain the data for one row. In order to analyze our data, we need to first remove the row containing the column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "[['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52'], ['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30'], ['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20'], ['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01'], ['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']]\n"
     ]
    }
   ],
   "source": [
    "headers = hn[0]\n",
    "hn = hn[1:]\n",
    "\n",
    "print(headers)\n",
    "print(hn[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extracting Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having removed the headers from the **hn** dataset, we are now ready to filter our data. Given that we only care about post titles beginning with **Ask HN** or **Show HN**, we'll create new lists of lists containing only the data for these titles, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1744 Ask HN posts.\n",
      "There are 1162 Show HN posts.\n",
      "There are 17194 other posts.\n"
     ]
    }
   ],
   "source": [
    "ask_posts, show_posts, other_posts = [], [], []\n",
    "\n",
    "for row in hn:\n",
    "    title = row[1]\n",
    "    title = title.lower()\n",
    "    if title.startswith('ask hn'):\n",
    "        ask_posts.append(row)\n",
    "    elif title.startswith('show hn'):\n",
    "        show_posts.append(row)\n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "\n",
    "print('There are {} Ask HN posts.'.format(len(ask_posts)))\n",
    "print('There are {} Show HN posts.'.format(len(show_posts)))\n",
    "print('There are {} other posts.'.format(len(other_posts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculating Average Number of Comments for Ask HN and Show HN Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's determine if ask posts or show posts receive more comments on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average number of comments on ask posts is 14.\n",
      "The average number of comments on show posts is 10.\n"
     ]
    }
   ],
   "source": [
    "total_ask_comments = 0\n",
    "for post in ask_posts:\n",
    "    n_comments = int(post[4])\n",
    "    total_ask_comments += n_comments\n",
    "avg_ask_comments = total_ask_comments / len(ask_posts)\n",
    "print('The average number of comments on ask posts is {:.0f}.'.format(avg_ask_comments))\n",
    "\n",
    "total_show_comments = 0\n",
    "for post in show_posts:\n",
    "    n_comments = int(post[4])\n",
    "    total_show_comments += n_comments\n",
    "avg_show_comments = total_show_comments / len(show_posts)\n",
    "print('The average number of comments on show posts is {:.0f}.'.format(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the findings from the analysis above, it appears that ask posts receive considerably more comments on average than show posts. This makes perfect sense because users who post questions would normally expect others to comment with answers to their ask posts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Finding the Number of Ask Posts and Comments by Hour Created"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we'll determine if ask posts created at a certain time are more likely to attract comments. We'll use the following steps to perform this analysis:\n",
    "1. Calculate the number of ask posts created in each hour of the day, along with the number of comments received\n",
    "2. Calculate the average number of comments ask posts receive by hour created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "\n",
    "result_list = []\n",
    "for post in ask_posts:\n",
    "    create_time = post[6]\n",
    "    n_comments = int(post[4])\n",
    "    result_list.append([create_time, n_comments])\n",
    "\n",
    "counts_by_hour, comments_by_hour = {}, {}\n",
    "for row in result_list:\n",
    "    date_str = row[0]\n",
    "    date = dt.datetime.strptime(date_str, '%m/%d/%Y %H:%M')\n",
    "    hour = dt.datetime.strftime(date, '%H')\n",
    "    if hour not in counts_by_hour:\n",
    "        counts_by_hour[hour] = 1\n",
    "        comments_by_hour[hour] = row[1]\n",
    "    else:\n",
    "        counts_by_hour[hour] += 1\n",
    "        comments_by_hour[hour] += row[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Calculating the Average Number of Comments for Ask HN Posts by Hour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we created two dictionaries:\n",
    "- **counts_by_hour**: contains the number of ask posts created during each hour of the day\n",
    "- **comments_by_hour**: contains the corresponding number of comments on ask posts created at each hour received\n",
    "\n",
    "Next, we'll use these two dictionaries to calculate the average number of comments for posts created during each hour of the day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['09', 251], ['13', 1253], ['10', 793], ['14', 1416], ['16', 1814], ['23', 543], ['12', 687], ['17', 1146], ['15', 4477], ['21', 1745], ['20', 1722], ['02', 1381], ['18', 1439], ['03', 421], ['05', 464], ['19', 1188], ['01', 683], ['22', 479], ['08', 492], ['04', 337], ['00', 447], ['06', 397], ['07', 267], ['11', 641]]\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour = []\n",
    "for hour in comments_by_hour:\n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]])\n",
    "print(avg_by_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Sorting and Printing Values from a List of Lists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have calculated the average number of comments for posts created during each hour of the day, and stored the results in a list of lists named **avg_by_hour**.\n",
    "\n",
    "However, the results are currently formatted in a way that makes if hard to identify the hours with the highest values. Let's finish off the task by sorting the list of lists and printing the five highest values in a format that's human readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 4477.00 average comments per post\n",
      "16:00: 1814.00 average comments per post\n",
      "21:00: 1745.00 average comments per post\n",
      "20:00: 1722.00 average comments per post\n",
      "18:00: 1439.00 average comments per post\n"
     ]
    }
   ],
   "source": [
    "swap_avg_by_hour = []\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "# print(swap_avg_by_hour)\n",
    "\n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse=True)\n",
    "print('Top 5 Hours for Ask Posts Comments')\n",
    "\n",
    "for avg, hour in sorted_swap[:5]:\n",
    "    hour = dt.datetime.strptime(hour, '%H')\n",
    "    hour = dt.datetime.strftime(hour, '%H:%M')\n",
    "    print('{}: {:.2f} average comments per post'.format(hour, avg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the above findings, the best time to create an Ask HN post is around mid-afternoon after 3pm but before 5pm. Certain hours in the evening before 10pm are also good times to post as commentors are pretty active during these hours also. Interestingly, posts created during the 3pm hour seem to receive by far the most comments; more than double that of the second best hour 4pm. This is quite likely the result of a extremely popular or viral post that happened to be posted at 3pm on a particular day which had significantly more comments than any other post, thus driving the average amount up."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
